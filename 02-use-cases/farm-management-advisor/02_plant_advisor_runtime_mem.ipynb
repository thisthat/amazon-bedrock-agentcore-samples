{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf99e376",
   "metadata": {},
   "source": [
    "# Plant Health AI Assistant - Runtime with Memory\n",
    "## Overview\n",
    "This notebook demonstrates how to deploy a LangGraph-based plant health analysis system with persistent memory capabilities using AWS Bedrock AgentCore. The system combines multi-agent orchestration with memory storage to provide intelligent plant diagnosis and historical tracking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1771f1",
   "metadata": {},
   "source": [
    "# Key Components\n",
    "1. Multi-Agent LangGraph Workflow\n",
    "Entry Router: Determines if query is for analysis or history retrieval\n",
    "\n",
    "Plant Detection Agent: Identifies plant type and health issues\n",
    "\n",
    "Care Agent: Provides expert treatment advice\n",
    "\n",
    "Web Search Agent: Finds latest research and recommendations\n",
    "\n",
    "Memory Agents: Save and retrieve plant analysis history\n",
    "\n",
    "2. AWS Bedrock AgentCore Memory\n",
    "Persistent storage for plant analysis sessions\n",
    "\n",
    "Actor-based memory isolation (farmer-specific)\n",
    "\n",
    "30-day retention for plant health tracking\n",
    "\n",
    "Conversation-style memory format\n",
    "\n",
    "3. Docker Deployment\n",
    "ARM64 container for AWS optimization\n",
    "\n",
    "Serverless scaling through AgentCore Runtime\n",
    "\n",
    "Production-ready with monitoring and error handling\n",
    "\n",
    "Prerequisites\n",
    "AWS Account with Bedrock AgentCore access\n",
    "\n",
    "Completed MCP Gateway setup (from previous notebook)\n",
    "\n",
    "Docker and AWS CLI configured\n",
    "\n",
    "Python 3.10+ environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66bfec9-e367-484f-ab2d-e99acf267371",
   "metadata": {},
   "source": [
    "# 01. Install dependencies and configure clients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6048ca82",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -r requirements.txt --no-cache-dir\n",
    "\n",
    "print(\"✅ Requirements installed. Now run the cells below.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081fc289-0c09-48e5-8e94-446ad65b28c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#restart kernel\n",
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b9ecec-7d81-40e8-b8c6-e9ef083645e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from typing import List, TypedDict, Any, Annotated\n",
    "import base64\n",
    "import random\n",
    "import string\n",
    "import shutil\n",
    "import uuid\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "\n",
    "from utils.utils import create_agentcore_role, create_agentcore_mem_role\n",
    "\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    " \n",
    "from bedrock_agentcore.runtime import BedrockAgentCoreApp\n",
    "from bedrock_agentcore.memory import MemoryClient\n",
    "from bedrock_agentcore_starter_toolkit.operations.gateway.client import GatewayClient\n",
    "from bedrock_agentcore_starter_toolkit.notebook import Runtime\n",
    "\n",
    "# Add this at the top of your notebook\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "# Core clients and variables\n",
    "sts_client = boto3.client('sts')\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "region = boto3.session.Session().region_name\n",
    "suffix = ''.join(random.choices(string.ascii_lowercase + string.digits, k=8))\n",
    "\n",
    "iam_client = boto3.client('iam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3743e5a7-0d44-4489-b569-ddf5377829e0",
   "metadata": {},
   "source": [
    "## Load notebook 01 configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff25cbb7-0e86-47e8-89dc-a5727ec4da41",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('plant_gateway_config.json', 'r') as f:\n",
    "        config = json.load(f)\n",
    "        \n",
    "    REGION = config['REGION']\n",
    "    GATEWAY_ID = config['GATEWAY_ID']\n",
    "    MCP_URL = config['GATEWAY_URL']\n",
    "    COGNITO_INFO = config['COGNITO_INFO']\n",
    "    \n",
    "    print(f\"Gateway ID: {GATEWAY_ID}\")\n",
    "    print(f\"Gateway URL: {MCP_URL}\")\n",
    "    print(f\"Region: {REGION}\")\n",
    "    print(\"✅ Configuration loaded successfully!\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"❌ Config file not found. Run the setup notebook first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e893c5-c57e-48cc-ba04-ca2162cb7736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the gateway client\n",
    "gateway_client = GatewayClient(region_name=REGION)\n",
    "\n",
    "# setup memory client\n",
    "memory_client = MemoryClient(region_name=REGION)\n",
    "\n",
    "# Get access token\n",
    "access_token = gateway_client.get_access_token_for_cognito(COGNITO_INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05942fb7-d965-42ec-b789-5f5084e4003b",
   "metadata": {},
   "source": [
    "# Create AgentCore Runtime and AgentCore Memory roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320ebde8-2633-4a5b-b80d-c5bbf8be2097",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_name = \"plant-advisor-agent-langgraph\"\n",
    "agentcore_iam_role = create_agentcore_role(agent_name=agent_name)\n",
    "\n",
    "print(f\"Runtime agent role: {agentcore_iam_role}\")\n",
    "print(\"✅ Runtime agent role successfully created!\")\n",
    "\n",
    "agentcore_mem_name = \"plant-advisor-mem-langgraph\"\n",
    "MEMORY_ROLE_ARN = create_agentcore_mem_role(agentcore_mem_name)\n",
    "\n",
    "print(f\"Memory agent role: {agentcore_iam_role}\")\n",
    "print(\"✅ Memory agent role successfully created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a550a79e-2f7c-4fa6-88fd-7e177c92416b",
   "metadata": {},
   "source": [
    "# Update configuration with Memory role and name for reuse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa496d5-dc49-44c3-ac09-1142f4f51ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unique memory name with timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "unique_memory_name = f\"PlantHealthAdvisor_{timestamp}\"\n",
    "\n",
    "# Load existing config\n",
    "try:\n",
    "    with open('plant_gateway_config.json', 'r') as f:\n",
    "        config = json.load(f)\n",
    "    \n",
    "    # Add memory role ARN\n",
    "    config['MEMORY_ROLE_ARN'] = MEMORY_ROLE_ARN\n",
    "    config['MEMORY_NAME'] = unique_memory_name\n",
    "    \n",
    "    # Write updated config\n",
    "    with open('plant_gateway_config.json', 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    \n",
    "    print(f\"✅ Added MEMORY_ROLE_ARN to config: {MEMORY_ROLE_ARN}\")\n",
    "    print(f\"   MEMORY_NAME: {unique_memory_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Failed to update config: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ee9800-b7e7-4e85-a049-b58e5832c3e6",
   "metadata": {},
   "source": [
    "# Create Memory Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c171408-fdcb-4118-9e4a-7bb02ce1162d",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_id = None\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\")\n",
    "logger = logging.getLogger(\"agentcore-memory\")\n",
    "\n",
    "ACTOR_ID = \"user_123\"\n",
    "SESSION_ID = \"plant_analysis_session_001\"  # Reuse same session for continuity\n",
    "\n",
    "#Create Memory Store\n",
    "try:\n",
    "    print(\"Creating Memory...\")\n",
    "    memory = memory_client.create_memory_and_wait(\n",
    "        name=unique_memory_name,\n",
    "        description=\"Plant Health Analysis Memory\",\n",
    "        strategies=[],  # No strategies for short-term memory\n",
    "        event_expiry_days=30,  # Keep plant analyses for 30 days\n",
    "        memory_execution_role_arn=MEMORY_ROLE_ARN,\n",
    "        max_wait=300,\n",
    "        poll_interval=10\n",
    "    )\n",
    "    \n",
    "    memory_id = memory['memoryId']\n",
    "    print(f\"✅ Memory created successfully with ID: {memory_id}\")\n",
    "    \n",
    "except ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'ValidationException' and \"already exists\" in str(e):\n",
    "        # Memory exists, get its ID\n",
    "        memories = memory_client.list_memories()\n",
    "        memory_id = next((m['id'] for m in memories if m['id'].startswith(memory_name)), None)\n",
    "        print(f\"✅ Memory already exists. Using existing memory ID: {memory_id}\")\n",
    "    else:\n",
    "        print(f\"❌ Memory creation error: {e}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ ERROR: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00766349-b466-4cc1-9706-d3458aff5a2e",
   "metadata": {},
   "source": [
    "# Langgraph definition and Prep Agent Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc756581-36d1-45ef-b7f1-8611f05ab4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize AgentCore App\n",
    "app = BedrockAgentCoreApp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6258d328-a44a-4250-8b02-085620458b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_mcp_response(result):\n",
    "    \"\"\"Parse nested MCP response\"\"\"\n",
    "    try:\n",
    "        if 'result' in result and 'content' in result['result']:\n",
    "            content = result['result']['content'][0]['text']\n",
    "            outer_json = json.loads(content)\n",
    "            if 'response' in outer_json and 'payload' in outer_json['response']:\n",
    "                body = outer_json['response']['payload']['body']\n",
    "                return json.loads(body)\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Parse error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff675900-fd3a-4e2b-ac21-9109353ac74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlantAnalysisState(TypedDict):\n",
    "    messages: Annotated[List[AnyMessage], add_messages]\n",
    "    prompt: str           # Add user query\n",
    "    query_type: str       # Add query type: \"analysis\" or \"history\"\n",
    "    image_path: str\n",
    "    image_data: str\n",
    "    plant_detection: dict\n",
    "    health_issues: str\n",
    "    expert_advice: str\n",
    "    web_search_results: str\n",
    "    final_report: str\n",
    "    memory_status: str    # Add memory operation status\n",
    "\n",
    "print(\"✅ Updated state definition with memory fields\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f95a20c-eac3-482a-a7e8-bff1007eb22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_mcp_tool(tool_name: str, arguments: dict, bearer_token: str):\n",
    "    \"\"\"Generic MCP tool caller\"\"\"\n",
    "    headers = {'Content-Type': 'application/json', 'Authorization': f'Bearer {bearer_token}'}\n",
    "    payload = {\n",
    "        \"jsonrpc\": \"2.0\",\n",
    "        \"id\": 3,\n",
    "        \"method\": \"tools/call\",\n",
    "        \"params\": {\"name\": tool_name, \"arguments\": arguments}\n",
    "    }\n",
    "    response = requests.post(MCP_URL, headers=headers, json=payload)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2693967e-930d-41b3-be11-98222ae0d374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plant_workflow():\n",
    "    \"\"\"Create plant analysis workflow using all three MCP tools + memory\"\"\"\n",
    "    workflow = StateGraph(PlantAnalysisState)\n",
    "    \n",
    "    # Keep ALL your existing functions exactly as they are\n",
    "    def detect_plant(state: PlantAnalysisState) -> dict:\n",
    "        \"\"\"Plant detection using MCP gateway tool\"\"\"\n",
    "        bearer_token = gateway_client.get_access_token_for_cognito(COGNITO_INFO)\n",
    "        image_path = state.get('image_path', '')\n",
    "        image_data = state.get('image_data', '')\n",
    "        print(f\"🔍 Starting plant detection for: {image_path}\")\n",
    "\n",
    "        try: \n",
    "            if image_data:\n",
    "                print(f\"✅ Using provided image_data: {len(image_data)} characters\")\n",
    "                result = call_mcp_tool(\"plant-detection-target___plant_detection_tool\", {\n",
    "                    \"image_data\": image_data\n",
    "                }, bearer_token)\n",
    "            elif image_path and not image_path.startswith('s3://') and image_path != \"from_image_data\":\n",
    "                if not os.path.exists(image_path):\n",
    "                    print(f\"❌ Image file not found: {image_path}\")\n",
    "                    return {\"plant_detection\": {\"plant_type\": \"error\"}, \"health_issues\": \"Image file not found\"}\n",
    "\n",
    "                with open(image_path, 'rb') as f:\n",
    "                    image_bytes = f.read()\n",
    "                    image_data_encoded = base64.b64encode(image_bytes).decode('utf-8')\n",
    "                    print(f\"✅ Image encoded: {len(image_data_encoded)} characters\")\n",
    "\n",
    "                result = call_mcp_tool(\"plant-detection-target___plant_detection_tool\", {\n",
    "                    \"image_data\": image_data_encoded\n",
    "                }, bearer_token)\n",
    "            else:\n",
    "                result = call_mcp_tool(\"plant-detection-target___plant_detection_tool\", {\n",
    "                    \"image_path\": image_path\n",
    "                }, bearer_token)\n",
    "\n",
    "            parsed_result = parse_mcp_response(result)\n",
    "\n",
    "            if parsed_result:\n",
    "                plant_name = parsed_result.get(\"plant_name\", \"unknown\")\n",
    "                health_issues = parsed_result.get(\"health_issues\", \"\")\n",
    "                print(f\"✅ Plant detected: {plant_name}\")\n",
    "                print(f\"📋 Health status: {health_issues}\")\n",
    "\n",
    "                return {\n",
    "                    \"plant_detection\": {\"plant_type\": plant_name},\n",
    "                    \"health_issues\": health_issues\n",
    "                }\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Plant detection error: {e}\")\n",
    "\n",
    "        return {\"plant_detection\": {\"plant_type\": \"error\"}, \"health_issues\": \"Detection failed\"}\n",
    "\n",
    "\n",
    "    # Fix for entry_router function - make it return a dict\n",
    "    def entry_router(state: PlantAnalysisState) -> dict:\n",
    "        \"\"\"Route based on query type - history or plant analysis\"\"\"\n",
    "        prompt = state.get(\"prompt\", \"\")\n",
    "        image_data = state.get(\"image_data\", \"\")\n",
    "        image_path = state.get(\"image_path\", \"\")\n",
    "        \n",
    "        # Check for history keywords\n",
    "        if prompt:\n",
    "            history_keywords = [\"show me\", \"previous\", \"compare\", \"history\", \"analyses\", \"month\", \"last time\"]\n",
    "            if any(keyword in prompt.lower() for keyword in history_keywords):\n",
    "                return {\"next\": \"retrieve_memory\"}\n",
    "        \n",
    "        # If has image data, go to plant detection\n",
    "        if image_data or image_path:\n",
    "            return {\"next\": \"detect_plant\"}\n",
    "        \n",
    "        return {\"next\": \"END\"}\n",
    "\n",
    "    # Keep your ORIGINAL router for analysis routing\n",
    "    def analysis_router(state: PlantAnalysisState) -> str:\n",
    "        \"\"\"Route based on plant detection results - your original logic\"\"\"\n",
    "        plant_detection = state.get(\"plant_detection\", {})\n",
    "        plant_name = plant_detection.get(\"plant_type\", \"\").lower()\n",
    "        health_issues = state.get(\"health_issues\", \"\").lower()\n",
    "        \n",
    "        if not plant_name or plant_name == \"error\":\n",
    "            return \"END\"\n",
    "        \n",
    "        # Check for critical issues\n",
    "        critical_keywords = [\"severe\", \"dying\", \"critical\", \"emergency\"]\n",
    "        if any(keyword in health_issues for keyword in critical_keywords):\n",
    "            return \"urgent_consultation\"\n",
    "        \n",
    "        return \"expert_consultation\"\n",
    "\n",
    "    # Keep all your existing functions unchanged\n",
    "    def plant_care_agent(state: PlantAnalysisState) -> dict:\n",
    "        \"\"\"Plant care using MCP gateway tool\"\"\"\n",
    "        bearer_token = gateway_client.get_access_token_for_cognito(COGNITO_INFO)\n",
    "        plant_info = state.get('plant_detection', {})\n",
    "        health_status = state.get('health_issues', '')\n",
    "        plant_name = plant_info.get('plant_type', 'unknown plant')\n",
    "        \n",
    "        print(f\"🌱 Getting care advice for: {plant_name}\")\n",
    "        print(f\"📋 Health status: {health_status}\")\n",
    "        \n",
    "        try:\n",
    "            result = call_mcp_tool(\"plant-care-target___plant_care_tool\", {\n",
    "                \"plant_name\": plant_name,\n",
    "                \"health_status\": health_status\n",
    "            }, bearer_token)\n",
    "            \n",
    "            parsed_result = parse_mcp_response(result)\n",
    "            \n",
    "            if parsed_result and 'expert_advice' in parsed_result:\n",
    "                advice = parsed_result['expert_advice']\n",
    "                print(f\"✅ Care advice received ({len(advice)} chars)\")\n",
    "                return {'expert_advice': advice}\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Plant care error: {e}\")\n",
    "        \n",
    "        return {'expert_advice': 'Plant care advice unavailable'}\n",
    "\n",
    "    def web_search_agent(state: PlantAnalysisState) -> dict:\n",
    "        \"\"\"Web search using MCP gateway tool\"\"\"\n",
    "        bearer_token = gateway_client.get_access_token_for_cognito(COGNITO_INFO)\n",
    "        plant_info = state.get('plant_detection', {})\n",
    "        health_status = state.get('health_issues', '')\n",
    "        plant_name = plant_info.get('plant_type', 'unknown plant')\n",
    "        \n",
    "        print(f\"🔍 Web searching for: {plant_name}\")\n",
    "        \n",
    "        try:\n",
    "            result = call_mcp_tool(\"plant-web-search-target___plant_web_search_tool\", {\n",
    "                \"plant_name\": plant_name,\n",
    "                \"health_status\": health_status\n",
    "            }, bearer_token)\n",
    "            \n",
    "            parsed_result = parse_mcp_response(result)\n",
    "            \n",
    "            if parsed_result:\n",
    "                search_results = parsed_result.get('web_search_results', str(parsed_result))\n",
    "                print(f\"✅ Web search completed ({len(search_results)} chars)\")\n",
    "                return {'web_search_results': search_results}\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Web search error: {e}\")\n",
    "        \n",
    "        return {'web_search_results': 'Web search unavailable'}\n",
    "\n",
    "    def expert_consultation_agent(state: PlantAnalysisState) -> dict:\n",
    "        \"\"\"Expert consultation with fallback to web search\"\"\"\n",
    "        care_result = plant_care_agent(state)\n",
    "        \n",
    "        if care_result.get('expert_advice') and 'unavailable' not in care_result.get('expert_advice', ''):\n",
    "            return care_result\n",
    "        \n",
    "        web_result = web_search_agent(state)\n",
    "        return {\n",
    "            'expert_advice': web_result.get('web_search_results', 'No advice available'),\n",
    "            'web_search_results': web_result.get('web_search_results', '')\n",
    "        }\n",
    "\n",
    "    def urgent_consultation_agent(state: PlantAnalysisState) -> dict:\n",
    "        \"\"\"Urgent consultation - uses both care and web search\"\"\"\n",
    "        care_result = plant_care_agent(state)\n",
    "        web_result = web_search_agent(state)\n",
    "        \n",
    "        expert_advice = care_result.get('expert_advice', '')\n",
    "        web_search_results = web_result.get('web_search_results', '')\n",
    "        \n",
    "        combined_advice = f\"\"\"**Expert Care Advice:**\n",
    "{expert_advice}\n",
    "\n",
    "**Additional Web Research:**\n",
    "{web_search_results}\"\"\"\n",
    "        \n",
    "        return {\n",
    "            'expert_advice': combined_advice,\n",
    "            'web_search_results': web_search_results\n",
    "        }\n",
    "    \n",
    "    def write_report(state: PlantAnalysisState) -> dict:\n",
    "        \"\"\"Generate final report\"\"\"\n",
    "        plant_info = state.get(\"plant_detection\", {})\n",
    "        health_issues = state.get(\"health_issues\", \"\")\n",
    "        expert_advice = state.get(\"expert_advice\", \"\")\n",
    "        web_search_results = state.get(\"web_search_results\", \"\")\n",
    "        \n",
    "        report = f\"\"\"# Plant Analysis Report\n",
    "\n",
    "## Detection Results\n",
    "- Plant Type: {plant_info.get('plant_type', 'Unknown')}\n",
    "- Health Assessment: {health_issues}\n",
    "\n",
    "## Expert Recommendations\n",
    "{expert_advice}\n",
    "\n",
    "## Analysis Method\n",
    "- Source: MCP Gateway Tools\n",
    "- Detection Tool: plant-detection-target___plant_detection_tool\n",
    "- Care Tool: plant-care-target___plant_care_tool\n",
    "- Search Tool: plant-web-search-target___plant_web_search_tool\n",
    "\"\"\"\n",
    "        \n",
    "        return {\"final_report\": report}\n",
    "    \n",
    "    # Memory functions\n",
    "    def retrieve_memory_agent(state: PlantAnalysisState) -> dict:\n",
    "        \"\"\"Retrieve plant analysis history from memory\"\"\"\n",
    "        try:\n",
    "            \n",
    "            events = memory_client.list_events(\n",
    "                memory_id=memory_id,\n",
    "                actor_id=actor_id,\n",
    "                session_id=session_id,\n",
    "                max_results=10\n",
    "            )\n",
    "            \n",
    "            if events:\n",
    "                history_summary = \"# Plant Analysis History\\n\\n\"\n",
    "                for i, event in enumerate(events, 1):\n",
    "                    history_summary += f\"{i}. {event}\\n\"\n",
    "            else:\n",
    "                history_summary = \"# Plant Analysis History\\n\\nNo previous analyses found.\"\n",
    "            \n",
    "            return {\n",
    "                \"final_report\": history_summary,\n",
    "                \"memory_status\": \"retrieved\"\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"final_report\": f\"# Memory Error\\n\\nCould not retrieve history: {str(e)}\",\n",
    "                \"memory_status\": \"error\"\n",
    "            }\n",
    "\n",
    "    def save_memory_agent(state: PlantAnalysisState) -> dict:\n",
    "        \"\"\"Save plant analysis to memory after report generation\"\"\"\n",
    "        try:\n",
    "            plant_info = state.get(\"plant_detection\", {})\n",
    "            health_issues = state.get(\"health_issues\", \"\")\n",
    "            expert_advice = state.get(\"expert_advice\", \"\")\n",
    "            \n",
    "            conversation = [\n",
    "                (f\"Plant analysis for {plant_info.get('plant_type', 'unknown plant')}\", \"USER\"),\n",
    "                (f\"Plant: {plant_info.get('plant_type')}\\nHealth: {health_issues}\\nAdvice: {expert_advice}\", \"ASSISTANT\")\n",
    "            ]\n",
    "            \n",
    "            memory_client.save_conversation(\n",
    "                memory_id=memory_id,\n",
    "                actor_id=actor_id,\n",
    "                session_id=session_id,\n",
    "                messages=conversation\n",
    "            )\n",
    "            \n",
    "            current_report = state.get(\"final_report\", \"\")\n",
    "            enhanced_report = current_report + f\"\\n\\n*Analysis saved to memory for future reference*\"\n",
    "            \n",
    "            return {\n",
    "                \"final_report\": enhanced_report,\n",
    "                \"memory_status\": \"saved\"\n",
    "            }\n",
    "        except Exception as e:\n",
    "            current_report = state.get(\"final_report\", \"\")\n",
    "            enhanced_report = current_report + f\"\\n\\n*Memory save failed: {str(e)}*\"\n",
    "            return {\n",
    "                \"final_report\": enhanced_report,\n",
    "                \"memory_status\": f\"save_failed: {str(e)}\"\n",
    "            }\n",
    "    \n",
    "    # Add all nodes\n",
    "    workflow.add_node(\"entry_router\", entry_router)              # NEW: Entry router\n",
    "    workflow.add_node(\"detect_plant\", detect_plant)\n",
    "    workflow.add_node(\"urgent_consultation\", urgent_consultation_agent)\n",
    "    workflow.add_node(\"expert_consultation\", expert_consultation_agent)\n",
    "    workflow.add_node(\"write_report\", write_report)\n",
    "    workflow.add_node(\"retrieve_memory\", retrieve_memory_agent)\n",
    "    workflow.add_node(\"save_memory\", save_memory_agent)\n",
    "    \n",
    "    # Build workflow with TWO routers\n",
    "    workflow.set_entry_point(\"entry_router\")  # Start with entry router\n",
    "\n",
    "    \n",
    "    # Then use it directly in conditional edges\n",
    "    workflow.add_conditional_edges(\n",
    "        \"entry_router\",\n",
    "        lambda state: state[\"next\"],  # ❌ This looks for \"next\" in workflow state\n",
    "        {\n",
    "            \"detect_plant\": \"detect_plant\",\n",
    "            \"retrieve_memory\": \"retrieve_memory\",\n",
    "            \"END\": END\n",
    "        }\n",
    "    )\n",
    "    # Analysis router edges (after plant detection)\n",
    "    workflow.add_conditional_edges(\n",
    "        \"detect_plant\",\n",
    "        analysis_router,  # Your original router logic\n",
    "        {\n",
    "            \"urgent_consultation\": \"urgent_consultation\",\n",
    "            \"expert_consultation\": \"expert_consultation\",\n",
    "            \"END\": END\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Analysis completion paths\n",
    "    workflow.add_edge(\"expert_consultation\", \"write_report\")\n",
    "    workflow.add_edge(\"urgent_consultation\", \"write_report\")\n",
    "    workflow.add_edge(\"write_report\", \"save_memory\")\n",
    "    workflow.add_edge(\"save_memory\", END)\n",
    "    \n",
    "    # History path\n",
    "    workflow.add_edge(\"retrieve_memory\", END)\n",
    "    \n",
    "    return workflow.compile(checkpointer=MemorySaver())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e731794-8d84-4ed5-a522-1505d64014fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@app.entrypoint\n",
    "def invoke(payload):\n",
    "    \"\"\"AgentCore entrypoint for LangGraph MCP workflow with memory support\"\"\"\n",
    "    # Truncate image_data for cleaner logging\n",
    "    log_payload = payload.copy()\n",
    "    if 'image_data' in log_payload and log_payload['image_data']:\n",
    "        log_payload['image_data'] = f\"{log_payload['image_data'][:50]}... ({len(log_payload['image_data'])} chars)\"\n",
    "    \n",
    "    print(f\"📥 Received payload: {log_payload}\")\n",
    "    \n",
    "    prompt = payload.get(\"prompt\", \"\")\n",
    "    image_path = payload.get(\"image_path\", \"\")\n",
    "    image_data = payload.get(\"image_data\", \"\")\n",
    "    \n",
    "    # Check if this is a history query\n",
    "    history_keywords = [\"show me\", \"previous\", \"compare\", \"history\", \"analyses\", \"month\", \"last time\"]\n",
    "    is_history_query = any(keyword in prompt.lower() for keyword in history_keywords) if prompt else False\n",
    "    \n",
    "    # Only require image for non-history queries\n",
    "    if not is_history_query and not image_path and not image_data:\n",
    "        return {\"error\": \"No image_path or image_data provided for plant analysis\", \"status\": \"failed\"}\n",
    "    \n",
    "    # Initialize state with all required fields\n",
    "    initial_state = {\n",
    "        \"messages\": [],\n",
    "        \"prompt\": prompt,                                      # ADD: For history detection\n",
    "        \"image_path\": image_path or \"from_image_data\",\n",
    "        \"image_data\": image_data,\n",
    "        \"plant_detection\": {},\n",
    "        \"health_issues\": \"\",\n",
    "        \"expert_advice\": \"\",\n",
    "        \"web_search_results\": \"\",\n",
    "        \"final_report\": \"\",\n",
    "        \"memory_status\": \"\"                                    # ADD: For memory operations\n",
    "    }\n",
    "    \n",
    "    config = {\"configurable\": {\"thread_id\": f\"agentcore_{random.randint(1000, 9999)}\"}}\n",
    "    \n",
    "    try:\n",
    "        final_state = langgraph_workflow.invoke(initial_state, config)\n",
    "        \n",
    "        return {\n",
    "            \"plant_type\": final_state.get('plant_detection', {}).get('plant_type', 'Unknown'),\n",
    "            \"health_issues\": final_state.get('health_issues', ''),\n",
    "            \"expert_advice\": final_state.get('expert_advice', ''),\n",
    "            \"web_search_results\": final_state.get('web_search_results', ''),\n",
    "            \"final_report\": final_state.get('final_report', ''),\n",
    "            \"memory_status\": final_state.get('memory_status', ''),    # ADD: Return memory status\n",
    "            \"status\": \"success\"\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Workflow error: {str(e)}\")\n",
    "        return {\"error\": str(e), \"status\": \"failed\"}\n",
    "\n",
    "print(\"✅ LangGraph MCP Workflow with Memory created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f97ff0-a3b4-4254-a50d-87fe280d7382",
   "metadata": {},
   "source": [
    "# Visualize LangGraph workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451984a7-f9e7-45be-b505-22475ad6830f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the workflow\n",
    "langgraph_workflow = create_plant_workflow()\n",
    "\n",
    "if langgraph_workflow is None:\n",
    "    print(\"❌ Workflow creation failed!\")\n",
    "else:\n",
    "    print(\"✅ LangGraph MCP Workflow created with all tools\")\n",
    "\n",
    "def visualize_enhanced_workflow():\n",
    "    \"\"\"Generate and display enhanced workflow graph\"\"\"\n",
    "    try:\n",
    "        # Check if workflow exists\n",
    "        if langgraph_workflow is None:\n",
    "            print(\"❌ Cannot visualize: workflow is None\")\n",
    "            return\n",
    "            \n",
    "        from IPython.display import Image, display\n",
    "        from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod\n",
    "        \n",
    "        # Use the already created workflow\n",
    "        display(Image(langgraph_workflow.get_graph().draw_mermaid_png(\n",
    "            curve_style=CurveStyle.LINEAR,\n",
    "            wrap_label_n_words=6,\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "            background_color=\"white\",\n",
    "            padding=25,\n",
    "            output_file_path=\"enhanced_plant_workflow.png\"\n",
    "        )))\n",
    "        \n",
    "        print(\"✅ Workflow graph saved as 'enhanced_plant_workflow.png'\")\n",
    "        print(\"🎯 Shows: Detection → Router → [Urgent/Expert] Consultation → Report\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Graph generation failed: {e}\")\n",
    "\n",
    "# Generate visualization AFTER workflow is created\n",
    "if langgraph_workflow is not None:\n",
    "    print(\"🎨 Generating workflow visualization...\")\n",
    "    visualize_enhanced_workflow()\n",
    "else:\n",
    "    print(\"❌ Skipping visualization - workflow creation failed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59acfca-1e6e-426c-8de2-bfc642d0af12",
   "metadata": {},
   "source": [
    "# Prep Runtime agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e88ac8f-6827-4b5b-8a4d-fbad5a87feb2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create project folder\n",
    "project_folder = \"plant_agent_runtime\"\n",
    "os.makedirs(project_folder, exist_ok=True)\n",
    "\n",
    "print(f\"✅ Created folder: {project_folder}\")\n",
    "\n",
    "# Create __init__.py file\n",
    "init_content = '''\"\"\"\n",
    "Plant Analysis Agent - LangGraph MCP Workflow with Memory\n",
    "\"\"\"\n",
    "\n",
    "__version__ = \"1.0.0\"\n",
    "__author__ = \"Plant Health Team\"\n",
    "'''\n",
    "\n",
    "with open(f\"{project_folder}/__init__.py\", 'w') as f:\n",
    "    f.write(init_content)\n",
    "\n",
    "print(\"✅ Created __init__.py\")\n",
    "\n",
    "# Copy requirements.txt\n",
    "files_to_copy = ['requirements.txt']\n",
    "\n",
    "for file_name in files_to_copy:\n",
    "    if os.path.exists(file_name):\n",
    "        shutil.copy(file_name, f\"{project_folder}/{file_name}\")\n",
    "        print(f\"✅ Copied: {file_name}\")\n",
    "    else:\n",
    "        print(f\"❌ Not found: {file_name}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87b6c43-5122-4790-a811-1c672f976625",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('plant_gateway_config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "workflow_code = f'''\n",
    "# plant_workflow_memory.py - Complete LangGraph MCP Workflow with Memory\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import boto3\n",
    "import string\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import json\n",
    "from typing import List, TypedDict, Any\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from typing import Annotated\n",
    "from bedrock_agentcore.runtime import BedrockAgentCoreApp\n",
    "from bedrock_agentcore.memory import MemoryClient\n",
    "from botocore.exceptions import ClientError\n",
    "import random\n",
    "import nest_asyncio\n",
    "import base64\n",
    "\n",
    "from bedrock_agentcore_starter_toolkit.operations.gateway.client import GatewayClient\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\")\n",
    "logger = logging.getLogger(\"agentcore-memory\")\n",
    "\n",
    "\n",
    "# Create unique memory name with timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "unique_memory_name = f\"PlantHealthAdvisor_{{timestamp}}\"\n",
    "\n",
    "\n",
    "# Initialize AgentCore App\n",
    "app = BedrockAgentCoreApp()\n",
    "\n",
    "\n",
    "# Load configuration\n",
    "try:\n",
    "   \n",
    "    \n",
    "    COGNITO_INFO = {config['COGNITO_INFO']}\n",
    "    REGION = '{config.get('REGION')}'\n",
    "    GATEWAY_ID = '{config['GATEWAY_ID']}'\n",
    "    MEMORY_ROLE_ARN = '{config['MEMORY_ROLE_ARN']}'\n",
    "\n",
    "    # setup the client\n",
    "    client = GatewayClient(region_name=REGION)\n",
    "    \n",
    "    \n",
    "    print(\"✅ Configuration loaded successfully!\")\n",
    "    print(f\"Gateway ID: {{GATEWAY_ID}}\")\n",
    "    print(f\"Region: {{REGION}}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"❌ Config file not found. Run the setup notebook first!\")\n",
    "    # Fallback to manual input\n",
    "    REGION = input(\"Enter the AWS region: \")\n",
    "    GATEWAY_ID = input(\"Enter Gateway ID: \")\n",
    "\n",
    "MCP_URL = '{config['GATEWAY_URL']}'\n",
    "\n",
    "# Memory configuration\n",
    "MEMORY_REGION = '{config['REGION']}'\n",
    "ACTOR_ID = \"user_123\"\n",
    "SESSION_ID = \"plant_analysis_session_001\"  # Reuse same session for continuity\n",
    "\n",
    "# Debug info that will be included in responses\n",
    "MEMORY_DEBUG = {{\n",
    "    \"memory_name\": unique_memory_name,\n",
    "    \"memory_region\": MEMORY_REGION,\n",
    "    \"memory_role_arn\": MEMORY_ROLE_ARN,\n",
    "    \"actor_id\": ACTOR_ID,\n",
    "    \"session_id\": SESSION_ID,\n",
    "    \"creation_attempt\": False,\n",
    "    \"creation_success\": False,\n",
    "    \"memory_id\": None,\n",
    "    \"error_details\": None\n",
    "}}\n",
    "\n",
    "# Initialize memory client and create memory\n",
    "try:\n",
    "    print(f\"Initializing memory client for region: {{MEMORY_REGION}}\")\n",
    "    memory_client = MemoryClient(region_name=MEMORY_REGION)\n",
    "    MEMORY_DEBUG[\"client_initialized\"] = True\n",
    "    \n",
    "    print(f\"Creating Memory with name: {{unique_memory_name}}\")\n",
    "    print(f\"Using role ARN: {{MEMORY_ROLE_ARN}}\")\n",
    "    MEMORY_DEBUG[\"creation_attempt\"] = True\n",
    "    \n",
    "    memory = memory_client.create_memory_and_wait(\n",
    "        name=unique_memory_name,\n",
    "        description=\"Plant Health Analysis Memory - Docker Container\",\n",
    "        strategies=[],\n",
    "        event_expiry_days=30,\n",
    "        memory_execution_role_arn=MEMORY_ROLE_ARN,\n",
    "        max_wait=300,\n",
    "        poll_interval=10\n",
    "    )\n",
    "\n",
    "    \n",
    "    MEMORY_ID = memory['memoryId']\n",
    "    print(f\"✅ Memory created successfully with ID: {{MEMORY_ID}}\")\n",
    "    MEMORY_DEBUG[\"creation_success\"] = True\n",
    "    MEMORY_DEBUG[\"memory_id\"] = MEMORY_ID\n",
    "    print(f\"✅ Memory created successfully with ID: {{MEMORY_ID}}\")\n",
    "    \n",
    "except ClientError as e:\n",
    "    MEMORY_DEBUG[\"client_error\"] = str(e)\n",
    "    MEMORY_DEBUG[\"error_code\"] = e.response.get('Error', {{}}).get('Code', 'Unknown')\n",
    "    \n",
    "    if e.response['Error']['Code'] == 'ValidationException' and \"already exists\" in str(e):\n",
    "        try:\n",
    "            memories = memory_client.list_memories()\n",
    "            MEMORY_ID = next((m['id'] for m in memories if m['id'].startswith(unique_memory_name)), None)\n",
    "            MEMORY_DEBUG[\"found_existing\"] = True\n",
    "            MEMORY_DEBUG[\"memory_id\"] = MEMORY_ID\n",
    "            print(f\"✅ Memory already exists. Using existing memory ID: {{MEMORY_ID}}\")\n",
    "        except Exception as list_error:\n",
    "            MEMORY_DEBUG[\"list_error\"] = str(list_error)\n",
    "            MEMORY_ID = None\n",
    "    else:\n",
    "        print(f\"❌ Memory creation error: {{e}}\")\n",
    "        MEMORY_DEBUG[\"error_details\"] = str(e)\n",
    "        MEMORY_ID = None\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Memory ERROR: {{e}}\")\n",
    "    MEMORY_DEBUG[\"general_error\"] = str(e)\n",
    "    memory_client = None\n",
    "    MEMORY_ID = None\n",
    "\n",
    "# Add debug info to startup message\n",
    "print(f\"🧠 Memory Debug Info: {{MEMORY_DEBUG}}\")\n",
    "\n",
    "# Get access token\n",
    "access_token = client.get_access_token_for_cognito(COGNITO_INFO)\n",
    "\n",
    "\n",
    "def parse_mcp_response(result):\n",
    "    \"\"\"Parse nested MCP response\"\"\"\n",
    "    try:\n",
    "        if 'result' in result and 'content' in result['result']:\n",
    "            content = result['result']['content'][0]['text']\n",
    "            outer_json = json.loads(content)\n",
    "            if 'response' in outer_json and 'payload' in outer_json['response']:\n",
    "                body = outer_json['response']['payload']['body']\n",
    "                return json.loads(body)\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Parse error: {{e}}\")\n",
    "        return None\n",
    "\n",
    "class PlantAnalysisState(TypedDict):\n",
    "    messages: Annotated[List[AnyMessage], add_messages]\n",
    "    prompt: str           # For history detection\n",
    "    query_type: str       # \"analysis\" or \"history\"\n",
    "    image_path: str\n",
    "    image_data: str\n",
    "    plant_detection: dict\n",
    "    health_issues: str\n",
    "    expert_advice: str\n",
    "    web_search_results: str\n",
    "    final_report: str\n",
    "    memory_status: str    # For memory operations\n",
    "\n",
    "def call_mcp_tool(tool_name: str, arguments: dict, bearer_token: str):\n",
    "    \"\"\"Generic MCP tool caller\"\"\"\n",
    "    headers = {{'Content-Type': 'application/json', 'Authorization': f'Bearer {{bearer_token}}'}}\n",
    "    payload = {{\n",
    "        \"jsonrpc\": \"2.0\",\n",
    "        \"id\": 3,\n",
    "        \"method\": \"tools/call\",\n",
    "        \"params\": {{\"name\": tool_name, \"arguments\": arguments}}\n",
    "    }}\n",
    "    response = requests.post(MCP_URL, headers=headers, json=payload)\n",
    "    return response.json()\n",
    "\n",
    "def create_plant_workflow():\n",
    "    \"\"\"Create plant analysis workflow with memory integration\"\"\"\n",
    "    workflow = StateGraph(PlantAnalysisState)\n",
    "    \n",
    "    def detect_plant(state: PlantAnalysisState) -> dict:\n",
    "        \"\"\"Plant detection using MCP gateway tool\"\"\"\n",
    "        bearer_token = client.get_access_token_for_cognito(COGNITO_INFO)\n",
    "\n",
    "        image_path = state.get('image_path', '')\n",
    "        image_data = state.get('image_data', '')\n",
    "        print(f\"🔍 Starting plant detection for: {{image_path}}\")\n",
    "\n",
    "        try: \n",
    "            if image_data:\n",
    "                print(f\"✅ Using provided image_data: {{len(image_data)}} characters\")\n",
    "                result = call_mcp_tool(\"plant-detection-target___plant_detection_tool\", {{\n",
    "                    \"image_data\": image_data\n",
    "                }}, bearer_token)\n",
    "            elif image_path and not image_path.startswith('s3://') and image_path != \"from_image_data\":\n",
    "                if not os.path.exists(image_path):\n",
    "                    print(f\"❌ Image file not found: {{image_path}}\")\n",
    "                    return {{\"plant_detection\": {{\"plant_type\": \"error\"}}, \"health_issues\": \"Image file not found\"}}\n",
    "\n",
    "                with open(image_path, 'rb') as f:\n",
    "                    image_bytes = f.read()\n",
    "                    image_data_encoded = base64.b64encode(image_bytes).decode('utf-8')\n",
    "                    print(f\"✅ Image encoded: {{len(image_data_encoded)}} characters\")\n",
    "\n",
    "                result = call_mcp_tool(\"plant-detection-target___plant_detection_tool\", {{\n",
    "                    \"image_data\": image_data_encoded\n",
    "                }}, bearer_token)\n",
    "            else:\n",
    "                result = call_mcp_tool(\"plant-detection-target___plant_detection_tool\", {{\n",
    "                    \"image_path\": image_path\n",
    "                }}, bearer_token)\n",
    "\n",
    "            parsed_result = parse_mcp_response(result)\n",
    "\n",
    "            if parsed_result:\n",
    "                plant_name = parsed_result.get(\"plant_name\", \"unknown\")\n",
    "                health_issues = parsed_result.get(\"health_issues\", \"\")\n",
    "                print(f\"✅ Plant detected: {{plant_name}}\")\n",
    "                print(f\"📋 Health status: {{health_issues}}\")\n",
    "\n",
    "                return {{\n",
    "                    \"plant_detection\": {{\"plant_type\": plant_name}},\n",
    "                    \"health_issues\": health_issues\n",
    "                }}\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Plant detection error: {{e}}\")\n",
    "\n",
    "        return {{\"plant_detection\": {{\"plant_type\": \"error\"}}, \"health_issues\": \"Detection failed\"}}\n",
    "\n",
    "    def entry_router(state: PlantAnalysisState) -> dict:\n",
    "        \"\"\"Route based on query type - history or plant analysis\"\"\"\n",
    "        prompt = state.get(\"prompt\", \"\")\n",
    "        image_data = state.get(\"image_data\", \"\")\n",
    "        image_path = state.get(\"image_path\", \"\")\n",
    "        \n",
    "        # Check for history keywords\n",
    "        if prompt:\n",
    "            history_keywords = [\"show me\", \"previous\", \"compare\", \"history\", \"analyses\", \"month\", \"last time\"]\n",
    "            if any(keyword in prompt.lower() for keyword in history_keywords):\n",
    "                return {{\"next\": \"retrieve_memory\"}}\n",
    "        \n",
    "        # If has image data, go to plant detection\n",
    "        if image_data or image_path:\n",
    "            return {{\"next\": \"detect_plant\"}}\n",
    "        \n",
    "        return {{\"next\": \"END\"}}\n",
    "    # Analysis router for plant detection results\n",
    "    def analysis_router(state: PlantAnalysisState) -> str:\n",
    "        \"\"\"Route based on plant detection results\"\"\"\n",
    "        plant_detection = state.get(\"plant_detection\", {{}})\n",
    "        plant_name = plant_detection.get(\"plant_type\", \"\").lower()\n",
    "        health_issues = state.get(\"health_issues\", \"\").lower()\n",
    "        \n",
    "        if not plant_name or plant_name == \"error\":\n",
    "            return \"END\"\n",
    "        \n",
    "        # Check for critical issues\n",
    "        critical_keywords = [\"severe\", \"dying\", \"critical\", \"emergency\"]\n",
    "        if any(keyword in health_issues for keyword in critical_keywords):\n",
    "            return \"urgent_consultation\"\n",
    "        \n",
    "        return \"expert_consultation\"\n",
    "\n",
    "    def plant_care_agent(state: PlantAnalysisState) -> dict:\n",
    "        \"\"\"Plant care using MCP gateway tool\"\"\"\n",
    "        bearer_token = client.get_access_token_for_cognito(COGNITO_INFO)\n",
    "\n",
    "\n",
    "        plant_info = state.get('plant_detection', {{}})\n",
    "        health_status = state.get('health_issues', '')\n",
    "        plant_name = plant_info.get('plant_type', 'unknown plant')\n",
    "        \n",
    "        print(f\"🌱 Getting care advice for: {{plant_name}}\")\n",
    "        print(f\"📋 Health status: {{health_status}}\")\n",
    "        \n",
    "        try:\n",
    "            result = call_mcp_tool(\"plant-care-target___plant_care_tool\", {{\n",
    "                \"plant_name\": plant_name,\n",
    "                \"health_status\": health_status\n",
    "            }}, bearer_token)\n",
    "            \n",
    "            parsed_result = parse_mcp_response(result)\n",
    "            \n",
    "            if parsed_result and 'expert_advice' in parsed_result:\n",
    "                advice = parsed_result['expert_advice']\n",
    "                print(f\"✅ Care advice received ({{len(advice)}} chars)\")\n",
    "                return {{'expert_advice': advice}}\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Plant care error: {{e}}\")\n",
    "        \n",
    "        return {{'expert_advice': 'Plant care advice unavailable'}}\n",
    "\n",
    "    def web_search_agent(state: PlantAnalysisState) -> dict:\n",
    "        \"\"\"Web search using MCP gateway tool\"\"\"\n",
    "        bearer_token = client.get_access_token_for_cognito(COGNITO_INFO)\n",
    "\n",
    "\n",
    "        plant_info = state.get('plant_detection', {{}})\n",
    "        health_status = state.get('health_issues', '')\n",
    "        plant_name = plant_info.get('plant_type', 'unknown plant')\n",
    "        \n",
    "        print(f\"🔍 Web searching for: {{plant_name}}\")\n",
    "        \n",
    "        try:\n",
    "            result = call_mcp_tool(\"plant-web-search-target___plant_web_search_tool\", {{\n",
    "                \"plant_name\": plant_name,\n",
    "                \"health_status\": health_status\n",
    "            }}, bearer_token)\n",
    "            \n",
    "            parsed_result = parse_mcp_response(result)\n",
    "            \n",
    "            if parsed_result:\n",
    "                search_results = parsed_result.get('web_search_results', str(parsed_result))\n",
    "                print(f\"✅ Web search completed ({{len(search_results)}} chars)\")\n",
    "                return {{'web_search_results': search_results}}\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Web search error: {{e}}\")\n",
    "        \n",
    "        return {{'web_search_results': 'Web search unavailable'}}\n",
    "\n",
    "    def expert_consultation_agent(state: PlantAnalysisState) -> dict:\n",
    "        \"\"\"Expert consultation with fallback to web search\"\"\"\n",
    "        care_result = plant_care_agent(state)\n",
    "        \n",
    "        if care_result.get('expert_advice') and 'unavailable' not in care_result.get('expert_advice', ''):\n",
    "            return care_result\n",
    "        \n",
    "        web_result = web_search_agent(state)\n",
    "        return {{\n",
    "            'expert_advice': web_result.get('web_search_results', 'No advice available'),\n",
    "            'web_search_results': web_result.get('web_search_results', '')\n",
    "        }}\n",
    "\n",
    "    def urgent_consultation_agent(state: PlantAnalysisState) -> dict:\n",
    "        \"\"\"Urgent consultation - uses both care and web search\"\"\"\n",
    "        care_result = plant_care_agent(state)\n",
    "        web_result = web_search_agent(state)\n",
    "        \n",
    "        expert_advice = care_result.get('expert_advice', '')\n",
    "        web_search_results = web_result.get('web_search_results', '')\n",
    "        \n",
    "        combined_advice = f\"\"\"**Expert Care Advice:**\n",
    "{{expert_advice}}\n",
    "\n",
    "**Additional Web Research:**\n",
    "{{web_search_results}}\"\"\"\n",
    "        \n",
    "        return {{\n",
    "            'expert_advice': combined_advice,\n",
    "            'web_search_results': web_search_results\n",
    "        }}\n",
    "    \n",
    "    def write_report(state: PlantAnalysisState) -> dict:\n",
    "        \"\"\"Generate final report\"\"\"\n",
    "        plant_info = state.get(\"plant_detection\", {{}})\n",
    "        health_issues = state.get(\"health_issues\", \"\")\n",
    "        expert_advice = state.get(\"expert_advice\", \"\")\n",
    "        web_search_results = state.get(\"web_search_results\", \"\")\n",
    "        \n",
    "        report = f\"\"\"# Plant Analysis Report\n",
    "\n",
    "## Detection Results\n",
    "- Plant Type: {{plant_info.get('plant_type', 'Unknown')}}\n",
    "- Health Assessment: {{health_issues}}\n",
    "\n",
    "## Expert Recommendations\n",
    "{{expert_advice}}\n",
    "\n",
    "## Analysis Method\n",
    "- Source: MCP Gateway Tools\n",
    "- Detection Tool: plant-detection-target___plant_detection_tool\n",
    "- Care Tool: plant-care-target___plant_care_tool\n",
    "- Search Tool: plant-web-search-target___plant_web_search_tool\n",
    "\"\"\"\n",
    "        \n",
    "        return {{\"final_report\": report}}\n",
    "    \n",
    "    # Memory functions with FIXED actor_id and session_id\n",
    "    def retrieve_memory_agent(state: PlantAnalysisState) -> dict:\n",
    "        \"\"\"Retrieve plant analysis history from memory\"\"\"\n",
    "        debug_info = {{\n",
    "        \"memory_client_available\": memory_client is not None,\n",
    "        \"memory_id\": MEMORY_ID,\n",
    "        \"actor_id\": ACTOR_ID,\n",
    "        \"session_id\": SESSION_ID\n",
    "    }}\n",
    "        try:\n",
    "            if not memory_client:\n",
    "                return {{\n",
    "                    \"final_report\": \"# Memory Error\\\\n\\\\nMemory client not initialized\",\n",
    "                    \"memory_status\": \"error\"\n",
    "                }}\n",
    "                \n",
    "            events = memory_client.list_events(\n",
    "                memory_id=MEMORY_ID,\n",
    "                actor_id=ACTOR_ID,\n",
    "                session_id=SESSION_ID,\n",
    "                max_results=10\n",
    "            )\n",
    "            debug_info[\"events_found\"] = len(events)\n",
    "            if events:\n",
    "                history_summary = \"# Plant Analysis History\\\\n\\\\n\"\n",
    "                for i, event in enumerate(events, 1):\n",
    "                    history_summary += f\"{{i}}. {{event}}\\\\n\"\n",
    "            else:\n",
    "                history_summary = \"# Plant Analysis History\\\\n\\\\nNo previous analyses found.\"\n",
    "            \n",
    "            return {{\n",
    "                \"final_report\": history_summary,\n",
    "                \"memory_status\": \"retrieved\"\n",
    "            }}\n",
    "        except Exception as e:\n",
    "            return {{\n",
    "                \"final_report\": f\"# Memory Error\\\\n\\\\nCould not retrieve history: {{str(e)}}\",\n",
    "                \"memory_status\": \"error\"\n",
    "            }}\n",
    "\n",
    "    def save_memory_agent(state: PlantAnalysisState) -> dict:\n",
    "        \"\"\"Save plant analysis to memory after report generation\"\"\"\n",
    "        debug_info = {{\n",
    "        \"memory_client_available\": memory_client is not None,\n",
    "        \"memory_id\": MEMORY_ID,\n",
    "        \"actor_id\": ACTOR_ID,\n",
    "        \"session_id\": SESSION_ID\n",
    "    }}\n",
    "        try:\n",
    "            if not memory_client:\n",
    "                print(\"⚠️ Memory client not available - continuing without memory\")\n",
    "                return {{\n",
    "                    \"final_report\": state.get(\"final_report\", \"\") + \"\\\\n\\\\n*Memory not available*\",\n",
    "                    \"memory_status\": \"error\"\n",
    "                }}\n",
    "                \n",
    "            plant_info = state.get(\"plant_detection\", {{}})\n",
    "            health_issues = state.get(\"health_issues\", \"\")\n",
    "            expert_advice = state.get(\"expert_advice\", \"\")\n",
    "            \n",
    "            conversation = [\n",
    "                (f\"Plant analysis for {{plant_info.get('plant_type', 'unknown plant')}}\", \"USER\"),\n",
    "                (f\"Plant: {{plant_info.get('plant_type')}}\\\\nHealth: {{health_issues}}\\\\nAdvice: {{expert_advice}}\", \"ASSISTANT\")\n",
    "            ]\n",
    "            \n",
    "            memory_client.save_conversation(\n",
    "                memory_id=MEMORY_ID,\n",
    "                actor_id=ACTOR_ID,\n",
    "                session_id=SESSION_ID,\n",
    "                messages=conversation\n",
    "            )\n",
    "            debug_info[\"save_successful\"] = True\n",
    "            current_report = state.get(\"final_report\", \"\")\n",
    "            enhanced_report = current_report + \"\\\\n\\\\n*Analysis saved to memory for future reference*\"\n",
    "            \n",
    "            return {{\n",
    "                \"final_report\": enhanced_report,\n",
    "                \"memory_status\": \"saved\"\n",
    "            }}\n",
    "        except Exception as e:\n",
    "            current_report = state.get(\"final_report\", \"\")\n",
    "            enhanced_report = current_report + f\"\\\\n\\\\n*Memory save failed: {{str(e)}}*\"\n",
    "            print(f\"⚠️ Memory operation failed: {{e}} - continuing without memory\")\n",
    "            return {{\n",
    "                \"final_report\": enhanced_report,\n",
    "                \"memory_status\": f\"save_failed: {{str(e)}}\"\n",
    "            }}\n",
    "\n",
    "    # Add all nodes\n",
    "    workflow.add_node(\"entry_router\", entry_router)\n",
    "    workflow.add_node(\"detect_plant\", detect_plant)\n",
    "    workflow.add_node(\"urgent_consultation\", urgent_consultation_agent)\n",
    "    workflow.add_node(\"expert_consultation\", expert_consultation_agent)\n",
    "    workflow.add_node(\"write_report\", write_report)\n",
    "    workflow.add_node(\"retrieve_memory\", retrieve_memory_agent)\n",
    "    workflow.add_node(\"save_memory\", save_memory_agent)\n",
    "    \n",
    "    # Build workflow with TWO routers\n",
    "    workflow.set_entry_point(\"entry_router\")  # Start with entry router\n",
    "\n",
    "    # Fix for conditional edges - extract the \"next\" key from the router's return value\n",
    "    # Then use it directly in conditional edges\n",
    "    workflow.add_conditional_edges(\n",
    "        \"entry_router\",\n",
    "        lambda state: state[\"next\"],  # ❌ This looks for \"next\" in workflow state\n",
    "        {{\n",
    "            \"detect_plant\": \"detect_plant\",\n",
    "            \"retrieve_memory\": \"retrieve_memory\",\n",
    "            \"END\": END\n",
    "        }}\n",
    "    )\n",
    "    # Analysis router edges (after plant detection)\n",
    "    workflow.add_conditional_edges(\n",
    "        \"detect_plant\",\n",
    "        analysis_router,  # Your original router logic\n",
    "        {{\n",
    "            \"urgent_consultation\": \"urgent_consultation\",\n",
    "            \"expert_consultation\": \"expert_consultation\",\n",
    "            \"END\": END\n",
    "        }}\n",
    "    )\n",
    "    \n",
    "    # Analysis completion paths\n",
    "    workflow.add_edge(\"expert_consultation\", \"write_report\")\n",
    "    workflow.add_edge(\"urgent_consultation\", \"write_report\")\n",
    "    workflow.add_edge(\"write_report\", \"save_memory\")\n",
    "    workflow.add_edge(\"save_memory\", END)\n",
    "    \n",
    "    # History path\n",
    "    workflow.add_edge(\"retrieve_memory\", END)\n",
    "    \n",
    "    return workflow.compile(checkpointer=MemorySaver())\n",
    "\n",
    "# Initialize the workflow\n",
    "langgraph_workflow = create_plant_workflow()\n",
    "\n",
    "@app.entrypoint\n",
    "def invoke(payload):\n",
    "    \"\"\"AgentCore entrypoint for LangGraph MCP workflow with memory support\"\"\"\n",
    "    # Truncate image_data for cleaner logging\n",
    "    log_payload = payload.copy()\n",
    "    if 'image_data' in log_payload and log_payload['image_data']:\n",
    "        log_payload['image_data'] = f\"{{log_payload['image_data'][:50]}}... ({{len(log_payload['image_data'])}} chars)\"\n",
    "    \n",
    "    print(f\"📥 Received payload: {{log_payload}}\")\n",
    "    \n",
    "    prompt = payload.get(\"prompt\", \"\")\n",
    "    image_path = payload.get(\"image_path\", \"\")\n",
    "    image_data = payload.get(\"image_data\", \"\")\n",
    "    \n",
    "    # Check if this is a history query\n",
    "    history_keywords = [\"show me\", \"previous\", \"compare\", \"history\", \"analyses\", \"month\", \"last time\"]\n",
    "    is_history_query = any(keyword in prompt.lower() for keyword in history_keywords) if prompt else False\n",
    "    \n",
    "    # Only require image for non-history queries\n",
    "    if not is_history_query and not image_path and not image_data:\n",
    "        return {{\"error\": \"No image_path or image_data provided for plant analysis\", \"status\": \"failed\"}}\n",
    "    \n",
    "    # Initialize state with all required fields\n",
    "    initial_state = {{\n",
    "        \"messages\": [],\n",
    "        \"prompt\": prompt,\n",
    "        \"query_type\": \"history\" if is_history_query else \"analysis\",\n",
    "        \"image_path\": image_path or \"from_image_data\",\n",
    "        \"image_data\": image_data,\n",
    "        \"plant_detection\": {{}},\n",
    "        \"health_issues\": \"\",\n",
    "        \"expert_advice\": \"\",\n",
    "        \"web_search_results\": \"\",\n",
    "        \"final_report\": \"\",\n",
    "        \"memory_status\": \"\"\n",
    "    }}\n",
    "    \n",
    "    config = {{\"configurable\": {{\"thread_id\": f\"agentcore_{{random.randint(1000, 9999)}}\"}}}}\n",
    "    \n",
    "    try:\n",
    "        final_state = langgraph_workflow.invoke(initial_state, config)\n",
    "        \n",
    "        return {{\n",
    "            \"plant_type\": final_state.get('plant_detection', {{}}).get('plant_type', 'Unknown'),\n",
    "            \"health_issues\": final_state.get('health_issues', ''),\n",
    "            \"expert_advice\": final_state.get('expert_advice', ''),\n",
    "            \"web_search_results\": final_state.get('web_search_results', ''),\n",
    "            \"final_report\": final_state.get('final_report', ''),\n",
    "            \"memory_status\": final_state.get('memory_status', ''),\n",
    "            \"debug_memory_id\": MEMORY_ID,  # ADD: Debug info\n",
    "            \"debug_actor_id\": ACTOR_ID,    # ADD: Debug info\n",
    "            \"debug_session_id\": SESSION_ID, # ADD: Debug info\n",
    "            \"status\": \"success\"\n",
    "        }}\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Workflow error: {{str(e)}}\")\n",
    "        return {{\"error\": str(e), \"status\": \"failed\"}}\n",
    "\n",
    "print(\"✅ Enhanced LangGraph MCP Workflow with Memory created\")\n",
    "\n",
    "# Add this to make it runnable\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🚀 Starting Plant Analysis Agent...\")\n",
    "    print(f\"🔗 Gateway: {{GATEWAY_ID}}\")\n",
    "    print(f\"🌐 MCP URL: {{MCP_URL}}\")\n",
    "    print(f\"🧠 Memory ID: {{MEMORY_ID}}\")\n",
    "    print(f\"👤 Actor ID: {{ACTOR_ID}}\")\n",
    "    print(f\"📝 Session ID: {{SESSION_ID}}\")\n",
    "    app.run()\n",
    "'''\n",
    "\n",
    "with open(f'{project_folder}/plant_workflow_memory.py', 'w') as f:\n",
    "    f.write(workflow_code)\n",
    "\n",
    "print(\"✅ Workflow saved to 'plant_workflow_memory.py'\")\n",
    "print(\"📝 Remember to update the configuration values in the file!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b09360-7ad7-4f5b-88d2-5029749f0b99",
   "metadata": {},
   "source": [
    "# Deploy using Starter toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10759e4-cd12-4dea-a9b2-994283a8624e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if Dockerfile exists and its content\n",
    "if os.path.exists('Dockerfile'):\n",
    "    with open('Dockerfile', 'r') as f:\n",
    "        content = f.read()\n",
    "    print(f\"Dockerfile size: {len(content)} bytes\")\n",
    "else:\n",
    "    print(\"No Dockerfile found\")\n",
    "\n",
    "# Remove corrupted files\n",
    "for file in ['Dockerfile', '.dockerignore', '.bedrock_agentcore.yaml']:\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)\n",
    "\n",
    "# Create fresh runtime and configure\n",
    "runtime = Runtime()\n",
    "config = runtime.configure(\n",
    "    entrypoint=f'{project_folder}/plant_workflow_memory.py',\n",
    "    requirements_file=f'{project_folder}/requirements.txt',\n",
    "    agent_name=\"plant_advisor_agent\",\n",
    "    auto_create_ecr=True,\n",
    "    execution_role=agentcore_iam_role['Role']['Arn']\n",
    ")\n",
    "\n",
    "# Verify Dockerfile was created properly\n",
    "if os.path.exists('Dockerfile'):\n",
    "    with open('Dockerfile', 'r') as f:\n",
    "        content = f.read()\n",
    "    print(f\"New Dockerfile size: {len(content)} bytes\")\n",
    "    if len(content) > 100:\n",
    "        print(\"✅ Dockerfile generated successfully\")\n",
    "        runtime.launch()\n",
    "    else:\n",
    "        print(\"❌ Dockerfile still corrupted\")\n",
    "else:\n",
    "    print(\"❌ Dockerfile not generated\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c09985e-9b95-45d2-94b0-94653db14a04",
   "metadata": {},
   "source": [
    "# Invoke runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c424cd-f53f-4a50-9456-33863b1086eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image_for_payload(image_path, max_size_kb=1024):\n",
    "    \"\"\"Resize image to fit within payload limits\"\"\"\n",
    "    \n",
    "    # Open and resize image\n",
    "    with Image.open(image_path) as img:\n",
    "        # Convert to RGB if necessary\n",
    "        if img.mode in ('RGBA', 'P'):\n",
    "            img = img.convert('RGB')\n",
    "        \n",
    "        # Start with reasonable dimensions\n",
    "        max_dimension = 800\n",
    "        \n",
    "        while True:\n",
    "            # Resize maintaining aspect ratio\n",
    "            img.thumbnail((max_dimension, max_dimension), Image.Resampling.LANCZOS)\n",
    "            \n",
    "            # Save to bytes\n",
    "            img_byte_arr = io.BytesIO()\n",
    "            img.save(img_byte_arr, format='JPEG', quality=85)\n",
    "            img_bytes = img_byte_arr.getvalue()\n",
    "            \n",
    "            # Check base64 size\n",
    "            base64_data = base64.b64encode(img_bytes).decode('utf-8')\n",
    "            size_kb = len(base64_data) / 1024\n",
    "            \n",
    "            print(f\"Resized to {img.size}, base64 size: {size_kb:.1f}KB\")\n",
    "            \n",
    "            if size_kb <= max_size_kb or max_dimension <= 200:\n",
    "                break\n",
    "                \n",
    "            max_dimension = int(max_dimension * 0.8)  # Reduce by 20%\n",
    "    \n",
    "    return base64_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140e1203-7404-4d46-a47d-02a4407a6908",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    print('🚀 Testing Plant Agent Runtime with real image...')\n",
    "    \n",
    "    # Read, resized, and encode the image file\n",
    "\n",
    "    resized_image_data = resize_image_for_payload('./Image/sweet_potato_leaf.png')\n",
    "    \n",
    "    # Test with resized image\n",
    "    test_payload = {\n",
    "        'prompt': 'Analyze my plant',\n",
    "        'image_data': resized_image_data\n",
    "    }\n",
    "    \n",
    "    response = runtime.invoke(payload=test_payload)\n",
    "    print(f'✅ Agent invocation successful!')\n",
    "    print(f'📝 Response Content Type: {response.get(\"contentType\")}')\n",
    "    \n",
    "    # Process response - FULL OUTPUT\n",
    "    if response.get(\"contentType\") == \"application/json\":\n",
    "        content = []\n",
    "        for chunk in response.get(\"response\", []):\n",
    "            content.append(chunk.decode('utf-8'))\n",
    "        result = json.loads(''.join(content))\n",
    "        \n",
    "        print(f\"\\n🌱 COMPLETE Plant Analysis Results:\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        print(f\"\\n📋 Plant Type: {result.get('plant_type', 'Unknown')}\")\n",
    "        \n",
    "        print(f\"\\n🔍 Health Assessment:\")\n",
    "        print(result.get('health_issues', 'None'))\n",
    "        \n",
    "        print(f\"\\n👨‍⚕️ Expert Advice:\")\n",
    "        print(result.get('expert_advice', 'No advice available'))\n",
    "        \n",
    "        if result.get('web_search_results'):\n",
    "            print(f\"\\n🔍 Web Search Results:\")\n",
    "            print(result.get('web_search_results'))\n",
    "        \n",
    "        print(f\"\\n📄 Final Report:\")\n",
    "        print(result.get('final_report', 'No report available'))\n",
    "        \n",
    "        print(f\"\\n✅ Status: {result.get('status', 'Unknown')}\")\n",
    "        \n",
    "        print(\"=\" * 80)\n",
    "    else:\n",
    "        print(f\"Raw response: {response}\")\n",
    "    \n",
    "    print('\\n🎉 Plant Agent Runtime working perfectly with real image data!')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f'❌ Agent invocation failed: {e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7012fe0-d157-493f-89c2-03cade60288f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def extract_clean_plant_analysis(response_data):\n",
    "    \"\"\"Extract clean, readable plant analysis\"\"\"\n",
    "    \n",
    "    response_bytes = response_data.get('response', [])\n",
    "    full_response = b''.join(response_bytes).decode('utf-8')\n",
    "    \n",
    "    try:\n",
    "        parsed_response = json.loads(full_response)\n",
    "        final_report = parsed_response.get('final_report', '')\n",
    "        \n",
    "        # Extract plant analysis sections\n",
    "        # Look for \"Plant: ... Health: ... Advice: ...\" patterns\n",
    "        plant_analyses = []\n",
    "        \n",
    "        # Split by numbered entries\n",
    "        entries = re.split(r'\\d+\\.\\s*{', final_report)\n",
    "        \n",
    "        for entry in entries[1:]:  # Skip the first split part\n",
    "            # Look for the text content within conversational data\n",
    "            text_matches = re.findall(r\"'text': '([^']*(?:\\\\.[^']*)*)'\", entry)\n",
    "            \n",
    "            for text in text_matches:\n",
    "                cleaned_text = text.replace('\\\\\\\\n', '\\n').replace(\"\\\\'\", \"'\")\n",
    "                \n",
    "                # Check if this looks like a plant analysis\n",
    "                if 'Plant:' in cleaned_text and 'Health:' in cleaned_text:\n",
    "                    # Split into sections\n",
    "                    sections = cleaned_text.split('\\n')\n",
    "                    \n",
    "                    plant_info = \"\"\n",
    "                    health_info = \"\"\n",
    "                    advice_info = \"\"\n",
    "                    current_section = None\n",
    "                    \n",
    "                    for line in sections:\n",
    "                        if line.startswith('Plant:'):\n",
    "                            plant_info = line\n",
    "                            current_section = 'plant'\n",
    "                        elif line.startswith('Health:'):\n",
    "                            health_info = line\n",
    "                            current_section = 'health'\n",
    "                        elif line.startswith('Advice:'):\n",
    "                            advice_info = line\n",
    "                            current_section = 'advice'\n",
    "                        elif current_section == 'health' and line.strip():\n",
    "                            health_info += \"\\n\" + line\n",
    "                        elif current_section == 'advice' and line.strip():\n",
    "                            advice_info += \"\\n\" + line\n",
    "                    \n",
    "                    if plant_info and health_info:\n",
    "                        plant_analyses.append({\n",
    "                            'plant': plant_info,\n",
    "                            'health': health_info,\n",
    "                            'advice': advice_info\n",
    "                        })\n",
    "        \n",
    "        return plant_analyses\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting analysis: {e}\")\n",
    "        return []\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487f5560-78e2-444b-9623-a54d6f3d8cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print('🚀 Testing Plant Agent Runtime memory...')\n",
    "    \n",
    "    # Testing memory\n",
    "    test_payload = {\n",
    "        'prompt': \"Show me my previous plant analyses\"\n",
    "    }\n",
    "    \n",
    "    response = runtime.invoke(payload=test_payload)\n",
    "    print(f'✅ Agent invocation successful!')\n",
    "    print(f'📝 Response Content Type: {response.get(\"contentType\")}')\n",
    "\n",
    "    # Process response - FULL OUTPUT\n",
    "    if response.get(\"contentType\") == \"application/json\":\n",
    "\n",
    "\n",
    "        # Extract the main content\n",
    "        response_bytes = response['response']\n",
    "        full_response = b''.join(response_bytes).decode('utf-8')\n",
    "        parsed = json.loads(full_response)\n",
    "\n",
    "        final_report= parsed.get('final_report')\n",
    "        \n",
    "        print(\"=== EXTRACTED CONTENT ===\")\n",
    "        print(f\"Status: {parsed.get('status')}\")\n",
    "        print(f\"Memory Status: {parsed.get('memory_status')}\")\n",
    "        print(f\"\\nFinal Report:\\n{final_report}\")\n",
    "\n",
    "        \n",
    "    print('\\n🎉 Plant Agent Runtime working perfectly with memory!')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f'❌ Agent invocation failed: {e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0347f428-c773-4f5e-baa8-7b29e5c98880",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
