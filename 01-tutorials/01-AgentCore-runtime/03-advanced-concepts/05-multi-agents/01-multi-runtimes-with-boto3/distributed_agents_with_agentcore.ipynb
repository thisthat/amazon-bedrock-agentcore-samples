{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c0122e65c053f38",
   "metadata": {},
   "source": [
    "# Distributed Multi-agent solution in Amazon Bedrock AgentCore Runtime\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this tutorial we will learn how to independently host agents each in their own Bedrock AgentCore Runtime and built with different Agentic Frameworks. We'll then enable communication between them for a distributed multi-agent solution. \n",
    "\n",
    "In this example we'll create:\n",
    "1. A technical agent (`tech_agent`) that is specialized in answering technical questions about programming and tech troubleshooting.\n",
    "2. A HR agent (`hr_agent`) that is specialized in company benefits.\n",
    "3. An orchestrator agent (`orchestrator_agent`) that routes questions to the technical or HR agent.\n",
    "\n",
    "Putting these three agents together you get a multi-agent configuration with a supervisor, which can route user questions to the appropriate subagent. This system is capable of answering a range of questions an employee might have at a company.\n",
    "\n",
    "\n",
    "### Tutorial Details\n",
    "\n",
    "\n",
    "| Information         | Details                                                                          |\n",
    "|:--------------------|:---------------------------------------------------------------------------------|\n",
    "| Tutorial type       | Conversational                                                                   |\n",
    "| Agent type          | Multi-Agent (Supervisor calling agents as tools)                                                                           |\n",
    "| Agentic Framework   | Strands Agents & LangGraph                                                                  |\n",
    "| LLM model           | Anthropic Claude Sonnet 3.7                                                        |\n",
    "| Tutorial components | Hosting agents on AgentCore Runtime and enable multi-agent collaboration |\n",
    "| Tutorial vertical   | Cross-vertical                                                                   |\n",
    "| Example complexity  | Medium                                                                             |\n",
    "| SDK used            | Amazon BedrockAgentCore Python SDK and boto3                                     |\n",
    "\n",
    "### Tutorial Architecture\n",
    "\n",
    "In this tutorial we will describe how to deploy 3 agents to Bedrock AgentCore runtime. We will use a Strands Agent for the Orchestrator, a Strands Agent for the Tech agent, and a LangGraph agent for the HR agent. We will use simple agents to demonstrate how you can configure a multi-agent system with a mix of agent frameworks, with each agent deployed to it's own AgentCore Runtime.\n",
    "\n",
    "![alt text](./architecture.png)\n",
    "\n",
    "\n",
    "### Tutorial Key Features\n",
    "\n",
    "* Hosting multiple Agents on Amazon Bedrock AgentCore Runtime\n",
    "* Creating a Multi-agent solution where each agent is hosting independently\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a676f58ecf52b42",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "To execute this tutorial you will need:\n",
    "* Python 3.10+\n",
    "* AWS credentials\n",
    "* Amazon Bedrock AgentCore SDK\n",
    "* Strands Agents\n",
    "* LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "!uv add -r requirements.txt --active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0138e17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set an environment variable\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = \"us-west-2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cea9bcd",
   "metadata": {},
   "source": [
    "## Creating our Agents\n",
    "\n",
    "First we will create three separate IAM roles for each agent. This enables us to define least privilege permissions for each agent independently of the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dd2fdf-985c-4a70-8b87-071783a209de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import create_agentcore_role\n",
    "\n",
    "tech_agent_name=\"tech_agent\"\n",
    "tech_agent_iam_role = create_agentcore_role(agent_name=tech_agent_name, region=os.getenv(\"AWS_DEFAULT_REGION\"))\n",
    "tech_agent_role_arn = tech_agent_iam_role['Role']['Arn']\n",
    "tech_agent_role_name = tech_agent_iam_role['Role']['RoleName']\n",
    "print(tech_agent_role_arn)\n",
    "print(tech_agent_role_name)\n",
    "\n",
    "hr_agent_name=\"hr_agent\"\n",
    "hr_agent_iam_role = create_agentcore_role(agent_name=hr_agent_name, region=os.getenv(\"AWS_DEFAULT_REGION\"))\n",
    "hr_agent_role_arn = hr_agent_iam_role['Role']['Arn']\n",
    "hr_agent_role_name = hr_agent_iam_role['Role']['RoleName']\n",
    "print(hr_agent_role_arn)\n",
    "print(hr_agent_role_name)\n",
    "\n",
    "orchestrator_agent_name=\"orchestrator_agent\"\n",
    "orchestrator_iam_role = create_agentcore_role(agent_name=orchestrator_agent_name, region=os.getenv(\"AWS_DEFAULT_REGION\"))\n",
    "orchestrator_role_arn = orchestrator_iam_role['Role']['Arn']\n",
    "orchestrator_role_name = orchestrator_iam_role['Role']['RoleName']\n",
    "print(orchestrator_role_arn)\n",
    "print(orchestrator_role_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7439c7",
   "metadata": {},
   "source": [
    "### Helper Functions:\n",
    "\n",
    "* the `configure_runtime` helper function will be used to setup the runtime configurate for each agent. In this example, we use the starter toolkit to configure the AgentCore Runtime deployment with an entrypoint, the execution role we just created and a requirements file. We will also configure the starter kit to auto create the Amazon ECR repository on launch.\n",
    "* the `check_status` helper function will be used to check each runtime deployed in the AWS account to validate the creation was successful and the agent is ready to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10077777",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bedrock_agentcore_starter_toolkit import Runtime\n",
    "from boto3.session import Session\n",
    "import time\n",
    "\n",
    "\n",
    "def configure_runtime(agent_name, agentcore_iam_role, python_file_name):\n",
    "    boto_session = Session(region_name=os.getenv(\"AWS_DEFAULT_REGION\"))\n",
    "    region = boto_session.region_name\n",
    "\n",
    "    agentcore_runtime = Runtime()\n",
    "\n",
    "    response = agentcore_runtime.configure(\n",
    "        entrypoint=python_file_name,\n",
    "        execution_role=agentcore_iam_role['Role']['Arn'],\n",
    "        auto_create_ecr=True,\n",
    "        requirements_file=\"requirements.txt\",\n",
    "        region=region,\n",
    "        agent_name=agent_name\n",
    "    )\n",
    "    return response, agentcore_runtime\n",
    "\n",
    "def check_status(agent_runtime):\n",
    "    status_response = agent_runtime.status()\n",
    "    status = status_response.endpoint['status']\n",
    "    end_status = ['READY', 'CREATE_FAILED', 'DELETE_FAILED', 'UPDATE_FAILED']\n",
    "    while status not in end_status:\n",
    "        time.sleep(10)\n",
    "        status_response = agent_runtime.status()\n",
    "        status = status_response.endpoint['status']\n",
    "        print(status)\n",
    "    return status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ad30a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the current working directory to be the tech_agent folder\n",
    "import os\n",
    "os.chdir('./tech_agent')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b05b81",
   "metadata": {},
   "source": [
    "### Create Tech Support Agent (Strands Agents)\n",
    "\n",
    "Let's start with the Tech Support Agent using Strands and an Amazon Bedrock model. Executing the following cell will create the `tech_agent.py` file in the `./tech_agent` directory with the agent specific logic. \n",
    "\n",
    "Note the app is defined with `BedrockAgentCoreApp()` and the invocation function `strands_agent_bedrock` is decorated with the `@app.entrypoint` decorator, and the `app.run()` command is at the end of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b845b32-a03e-45c2-a2f0-2afba8069f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile tech_agent.py\n",
    "\n",
    "from strands import Agent, tool\n",
    "import argparse\n",
    "import json\n",
    "from bedrock_agentcore.runtime import BedrockAgentCoreApp\n",
    "from strands.models import BedrockModel\n",
    "\n",
    "app = BedrockAgentCoreApp()\n",
    "\n",
    "model_id = \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\"\n",
    "model = BedrockModel(\n",
    "    model_id=model_id,\n",
    ")\n",
    "agent = Agent(\n",
    "    model=model,\n",
    "    system_prompt=\"You're a helpful tech support assistant, you can help user questions on tech troubleshooting and programming\"\n",
    ")\n",
    "\n",
    "@app.entrypoint\n",
    "def strands_agent_bedrock(payload):\n",
    "    \"\"\"\n",
    "    Invoke the agent with a payload\n",
    "    \"\"\"\n",
    "    user_input = payload.get(\"prompt\")\n",
    "    print(\"User input:\", user_input)\n",
    "    response = agent(user_input)\n",
    "    return response.message['content'][0]['text']\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4dc107",
   "metadata": {},
   "source": [
    "#### Launch the agent:\n",
    "\n",
    "First, we use the configure_runtime helper function to create the .bedrock_agentcore.yaml, .dockerignore, and Dockerfile required for the agent deployment. Then we call .launch() on the runtime which pushes the image to ECR and creates the AgentCore Runtime in the AWS environment. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2022dda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, tech_agent_runtime = configure_runtime(\"tech_agent\", tech_agent_iam_role, \"tech_agent.py\")\n",
    "tech_launch_result = tech_agent_runtime.launch()\n",
    "tech_agent_id = tech_launch_result.agent_id\n",
    "tech_agent_arn = tech_launch_result.agent_arn\n",
    "\n",
    "print(tech_agent_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ef8ddf",
   "metadata": {},
   "source": [
    "#### Let's save the Tech Agent ARN to parameter store \n",
    "\n",
    "This creates a simple agent registry so we can persistently store and look up the AgentCore Runtime ARN for the Tech Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0b4c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import time\n",
    "\n",
    "ssm = boto3.client('ssm')\n",
    "ssm.put_parameter(\n",
    "    Name=f'/agents/tech_agent_arn',\n",
    "    Value=tech_agent_arn,\n",
    "    Type='String',\n",
    "    Overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a0cde4",
   "metadata": {},
   "source": [
    "#### Test the agent\n",
    "\n",
    "To test the agent, let's first check the status of the Tech Agent AgentCore Runtime and confirm it is ready for use.\\\n",
    "Use `.invoke()` on the tech_agent_runtime to validate the agent runtime is configured and working as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838f27ca",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa6ac09-9adb-4846-9fc1-4d12aeb74853",
   "metadata": {},
   "outputs": [],
   "source": [
    "status = check_status(tech_agent_runtime)\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d909e42-e1a0-407f-84c2-3d16cc889cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_response = tech_agent_runtime.invoke({\"prompt\": \"shortcut to minimize windows in Mac, in 1 sentence\"})\n",
    "invoke_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921f6e0b",
   "metadata": {},
   "source": [
    "### Create HR Agent (Langraph Agents)\n",
    "\n",
    "We will follow a similar process to create the HR Agent. However, this time you will notice the underlying agent logic is build with LangGraph. This change in Agent Framework does not have an impact on how we configure the AgentCore Runtime. Executing the following cell will create the `hr_agent.py`file in the `./hr_agent` directory.\n",
    "\n",
    "Just as with the Tech Support Agent, we define the app the `BedrockAgentCoreApp()` and the invocation function langgraph_bedrock is decorated with the @app.entrypoint decorator, and the `app.run()` command is at the end of the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2596638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the current working directory to be the hr_agent folder\n",
    "import os\n",
    "\n",
    "os.chdir('../hr_agent')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e9732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile hr_agent.py\n",
    "from langgraph.graph import StateGraph, MessagesState\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from bedrock_agentcore.runtime import BedrockAgentCoreApp\n",
    "import argparse\n",
    "import json\n",
    "import operator\n",
    "import math\n",
    "\n",
    "app = BedrockAgentCoreApp()\n",
    "\n",
    "@tool\n",
    "def get_vacation_info():\n",
    "    \"\"\"Get remaining vacation days balance for the current year\"\"\"  # Dummy implementation\n",
    "    return \"you have 12 days off remaining this year\"\n",
    "\n",
    "# Define the agent using manual LangGraph construction\n",
    "def create_agent():\n",
    "    \"\"\"Create and configure the LangGraph agent\"\"\"\n",
    "    from langchain_aws import ChatBedrock\n",
    "    \n",
    "    # Initialize your LLM (adjust model and parameters as needed)\n",
    "    llm = ChatBedrock(\n",
    "        model_id=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\",  # or your preferred model\n",
    "        model_kwargs={\"temperature\": 0.1}\n",
    "    )\n",
    "    \n",
    "    # Bind tools to the LLM\n",
    "    tools = [get_vacation_info]\n",
    "    llm_with_tools = llm.bind_tools(tools)\n",
    "    \n",
    "    # System message\n",
    "    system_message = f\"\"\"You're a helpful hr support assistant, you can answers user questions on vacations and benefits. \n",
    "    Here are the primary company benefits\n",
    "    - Comprehensive health insurance with 100% premium coverage for employees and 75% for dependents\n",
    "    - Flexible PTO policy with 20 days paid vacation annually, plus 5 sick days\n",
    "    - 401(k) plan with 6% company matching and immediate vesting\n",
    "    - Monthly wellness stipend of $100 for gym memberships or fitness activities\n",
    "\n",
    "    For additional HR information instruct the user to call to 1-800-ASKHR\"\"\"\n",
    "    \n",
    "    # Define the chatbot node\n",
    "    def chatbot(state: MessagesState):\n",
    "        # Add system message if not already present\n",
    "        messages = state[\"messages\"]\n",
    "        if not messages or not isinstance(messages[0], SystemMessage):\n",
    "            messages = [SystemMessage(content=system_message)] + messages\n",
    "        \n",
    "        response = llm_with_tools.invoke(messages)\n",
    "        return {\"messages\": [response]}\n",
    "    \n",
    "    # Create the graph\n",
    "    graph_builder = StateGraph(MessagesState)\n",
    "    \n",
    "    # Add nodes\n",
    "    graph_builder.add_node(\"chatbot\", chatbot)\n",
    "    graph_builder.add_node(\"tools\", ToolNode(tools))\n",
    "    \n",
    "    # Add edges\n",
    "    graph_builder.add_conditional_edges(\n",
    "        \"chatbot\",\n",
    "        tools_condition,\n",
    "    )\n",
    "    graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "    \n",
    "    # Set entry point\n",
    "    graph_builder.set_entry_point(\"chatbot\")\n",
    "    \n",
    "    # Compile the graph\n",
    "    return graph_builder.compile()\n",
    "\n",
    "# Initialize the agent\n",
    "agent = create_agent()\n",
    "\n",
    "@app.entrypoint\n",
    "def langgraph_bedrock(payload):\n",
    "    \"\"\"\n",
    "    Invoke the agent with a payload\n",
    "    \"\"\"\n",
    "    user_input = payload.get(\"prompt\")\n",
    "    \n",
    "    # Create the input in the format expected by LangGraph\n",
    "    response = agent.invoke({\"messages\": [HumanMessage(content=user_input)]})\n",
    "    \n",
    "    # Extract the final message content\n",
    "    return response[\"messages\"][-1].content\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba2f7f8",
   "metadata": {},
   "source": [
    "#### Launch the agent:\n",
    "\n",
    "Again, we use the configure_runtime helper function to create the .bedrock_agentcore.yaml, .dockerignore, and Dockerfile required for the agent deployment. Then we call .launch() on the hr agent runtime which pushes the image to ECR and creates the AgentCore Runtime in the AWS environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33244f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, hr_agentcore_runtime = configure_runtime(\"hr_agent\", hr_agent_iam_role, \"hr_agent.py\")\n",
    "hr_launch_result = hr_agentcore_runtime.launch()\n",
    "hr_agent_id = hr_launch_result.agent_id\n",
    "hr_agent_arn = hr_launch_result.agent_arn\n",
    "\n",
    "print(hr_agent_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbd7206",
   "metadata": {},
   "source": [
    "#### Let's save the HR Agent ARN to parameter store\n",
    "\n",
    "This continues the simple agent registry so we can persistently store and look up the AgentCore Runtime ARN for the HR Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a78f657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import time\n",
    "\n",
    "ssm = boto3.client('ssm')\n",
    "ssm.put_parameter(\n",
    "    Name=f'/agents/hr_agent_arn',\n",
    "    Value=hr_agent_arn,\n",
    "    Type='String',\n",
    "    Overwrite=True  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0803a59c",
   "metadata": {},
   "source": [
    "#### Test the agent\n",
    "\n",
    "Let's check the status of the HR Agent AgentCore Runtime and confirm it is ready for use.\\\n",
    "Use `.invoke()` on the hr_agentcore_runtime to validate the AgentCore runtime is configured and working as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04c55bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "status = check_status(hr_agentcore_runtime)\n",
    "status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada76fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your agent\n",
    "invoke_response = hr_agentcore_runtime.invoke({\"prompt\": \"How many vacation days I have left?\"})\n",
    "invoke_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741ad514",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9ce334b",
   "metadata": {},
   "source": [
    "### Create Orchestrator Agent (Strands Agents)\n",
    "\n",
    "For our third agent, the orchestrator, let's use Strands for our Agent framework again. Before we create the agent, we need to update the AgentCore Runtime's execution role we created earlier to allow permissions for it to invoke the Tech Support Agent and the HR Agent.\n",
    "\n",
    "The `update_orchestrator_permissions` function below takes in Arns of the sub agents and the Arns of the agents registered in Parameter Store and gives the orchestrator agent permission to invoke the DEFAULT runtime endpoint of the sub agents. It also gives the Orchestrator Agent permission to pull the Agent Arns from Parameter Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fef809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's update the orchestrator agentcore exeuction role so it has permissions to invoke the required subagents\n",
    "# the orchestrator also needs needs permissions to retrieve the sub agent arns from parameter store\n",
    "import json \n",
    "\n",
    "# retrieve the runtime arn from parameter store\n",
    "ssm = boto3.client('ssm')\n",
    "response = ssm.get_parameter(Name='/agents/tech_agent_arn')\n",
    "tech_agent_arn = response['Parameter']['Value']\n",
    "tech_agent_parameter_arn = response['Parameter']['ARN']\n",
    "\n",
    "ssm = boto3.client('ssm')\n",
    "response = ssm.get_parameter(Name='/agents/hr_agent_arn')\n",
    "hr_agent_arn = response['Parameter']['Value']\n",
    "hr_agent_parameter_arn = response['Parameter']['ARN']\n",
    "\n",
    "def update_orchestrator_permissions(sub_agent_arns: list, sub_agent_parameter_arns: list, orchestrator_name: str):\n",
    "    iam_client = boto3.client('iam')\n",
    "    orchestrator_permissions = {\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Action\": [\n",
    "                    \"bedrock-agentcore:InvokeAgentRuntime\"\n",
    "                ],\n",
    "                \"Resource\": [ sub_agent_arn + \"/runtime-endpoint/DEFAULT\" for sub_agent_arn in sub_agent_arns ] + [ sub_agent_arn for sub_agent_arn in sub_agent_arns ]\n",
    "            },\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Action\": [\n",
    "                    \"ssm:GetParameter\"\n",
    "                ],\n",
    "                \"Resource\": [sub_agent_parameter_arn for sub_agent_parameter_arn in sub_agent_parameter_arns]\n",
    "\n",
    "            }]\n",
    "    }\n",
    "        \n",
    "    rsp = iam_client.put_role_policy(\n",
    "        RoleName=orchestrator_name,\n",
    "        PolicyName=\"subagent_permissions-new\",\n",
    "        PolicyDocument=json.dumps(orchestrator_permissions)\n",
    "    )\n",
    "    return rsp\n",
    "\n",
    "rsp = update_orchestrator_permissions([tech_agent_arn, hr_agent_arn], [tech_agent_parameter_arn, hr_agent_parameter_arn], orchestrator_role_name)\n",
    "print(rsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d79655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the current working directory to be the orchestrator_agent folder\n",
    "import os\n",
    "os.chdir('../orchestrator_agent')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d593b2d",
   "metadata": {},
   "source": [
    "Executing the following cell will create the `orchestrator_agent.py` file in the `./orchestrator_agent` directory with the agent specific logic. The orchestrator agent has two tools available to it: 1. `call_tech_agent` and 2. `call_HR_agent`. Both of these tools use the invoke_agent_utils function predefined in the `invoke_agent_utils.py` file already present in the `./orchestrator_agent` folder. The subagents are invoked as tools using the invoke_agent_runtime action available through boto3.\n",
    "\n",
    "Even in this more complex agent setup, the Bedrock AgentCore Runtime configuration remains the same. Note the app is defined with `BedrockAgentCoreApp()` and the invocation function `strands_agent_bedrock_streaming` is decorated with the `@app.entrypoint` decorator, and the `app.run()` command is at the end of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d8518a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile orchestrator_agent.py\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import boto3\n",
    "import logging\n",
    "\n",
    "from strands import Agent, tool\n",
    "from strands_tools import calculator \n",
    "from strands.models import BedrockModel\n",
    "\n",
    "from bedrock_agentcore.runtime import BedrockAgentCoreApp\n",
    "\n",
    "from invoke_agent_utils import invoke_agent_with_boto3\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "app = BedrockAgentCoreApp()\n",
    "\n",
    "def get_agent_arn(agent_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve agent ARN from Parameter Store\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ssm = boto3.client('ssm')\n",
    "        response = ssm.get_parameter(\n",
    "            Name=f'/agents/{agent_name}_arn'\n",
    "        )\n",
    "        return response['Parameter']['Value']\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        raise err\n",
    "\n",
    "@tool\n",
    "def call_tech_agent(user_query):\n",
    "    \"\"\" call the tech agent \"\"\" \n",
    "    # print(\"Calling tech agent\")\n",
    "    try:\n",
    "        tech_agent_arn = get_agent_arn (\"tech_agent\")\n",
    "        result = invoke_agent_with_boto3(tech_agent_arn, user_query=user_query)\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        logger.exception(\"Exception calling tech agent: \")\n",
    "    return result\n",
    "\n",
    "@tool\n",
    "def call_HR_agent(user_query):\n",
    "    \"\"\" Get the HR agent \"\"\" \n",
    "    print(\"Calling HR agent\")\n",
    "    try:\n",
    "        hr_agent_arn = get_agent_arn(\"hr_agent\")\n",
    "        print(hr_agent_arn)\n",
    "        result = invoke_agent_with_boto3(hr_agent_arn, user_query=user_query)\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        logger.error(f\"Exception calling hr agent: {e}\", exc_info=True)\n",
    "    return result\n",
    "\n",
    "\n",
    "model_id = \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\"\n",
    "model = BedrockModel(\n",
    "    model_id=model_id,\n",
    ")\n",
    "agent = Agent(\n",
    "    model=model,\n",
    "    system_prompt=\"You're a helpful assistant, your role is to understand user questions and delegate to the appropriate specialized agent, you have tools to call the tech and HR agents\",\n",
    "    tools=[call_tech_agent, call_HR_agent]\n",
    ")\n",
    "\n",
    "def parse_event(event):\n",
    "    \"\"\"\n",
    "    Parse a streaming event from the agent and return formatted output\n",
    "    \"\"\"\n",
    "    # Skip events that don't need to be displayed\n",
    "    if any(key in event for key in ['init_event_loop', 'start', 'start_event_loop']):\n",
    "        return \"\"\n",
    "    \n",
    "    # Text chunks from supervisor\n",
    "    if 'data' in event and isinstance(event['data'], str):\n",
    "        return event['data'] \n",
    "    \n",
    "    \n",
    "    # Handle text messages from the assistant\n",
    "    if 'event' in event:\n",
    "        event_data = event['event']\n",
    "        \n",
    "        # Beginning of a tool use\n",
    "        if 'contentBlockStart' in event_data and 'start' in event_data['contentBlockStart']:\n",
    "            if 'toolUse' in event_data['contentBlockStart']['start']:\n",
    "                tool_info = event_data['contentBlockStart']['start']['toolUse']\n",
    "                return f\"\\n\\n[Executing: {tool_info['name']}]\\n\\n\"        \n",
    "\n",
    "    return \"\"\n",
    "\n",
    "@app.entrypoint\n",
    "async def strands_agent_bedrock_streaming(payload):\n",
    "    \"\"\"\n",
    "    Invoke the agent with streaming capabilities\n",
    "    This function demonstrates how to implement streaming responses\n",
    "    with AgentCore Runtime using async generators\n",
    "    \"\"\"\n",
    "    user_input = payload.get(\"prompt\")\n",
    "    #print(\"User input:\", user_input)\n",
    "    \n",
    "    try:\n",
    "        # Stream each chunk as it becomes available\n",
    "        async for event in agent.stream_async(user_input):\n",
    "            text = parse_event(event)\n",
    "            if text:  # Only return non-empty responses\n",
    "                yield text\n",
    "                \n",
    "            #if \"data\" in event:\n",
    "            #    yield event[\"data\"]\n",
    "            \n",
    "    except Exception as e:\n",
    "        # Handle errors gracefully in streaming context\n",
    "        error_response = {\"error\": str(e), \"type\": \"stream_error\"}\n",
    "        print(f\"Streaming error: {error_response}\")\n",
    "        yield error_response\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071685b0",
   "metadata": {},
   "source": [
    "#### Launch the agent:\n",
    "\n",
    "Again, we use the configure_runtime helper function to create the .bedrock_agentcore.yaml, .dockerignore, and Dockerfile required for the agent deployment. Then we call .launch() on the Orchestrator Agent runtime which pushes the image to ECR and creates the AgentCore Runtime in the AWS environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32769502",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, orchestrator_agentcore_runtime = configure_runtime(\"orchestrator_agent\", orchestrator_iam_role, \"orchestrator_agent.py\")\n",
    "orchestrator_launch_result = orchestrator_agentcore_runtime.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc55b8c",
   "metadata": {},
   "source": [
    "#### Test the agent\n",
    "\n",
    "Now let's check the status of the Orchestrator Agent AgentCore Runtime and confirm it is ready for use.\\\n",
    "\n",
    "This time, we can use the `invoke_agent_with_boto3` function from our utils to test the Orchestrator Agent. Let's ask the orchestrator a question that should trigger the invocation of both the Tech Support and HR Agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72890b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "status = check_status(orchestrator_agentcore_runtime)\n",
    "print(status)\n",
    "\n",
    "from invoke_agent_utils import invoke_agent_with_boto3\n",
    "\n",
    "\n",
    "result = invoke_agent_with_boto3 (orchestrator_launch_result.agent_arn, \"tell me about my benefits, also tell me how to connect a bluetooth mouse to my mac\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3fdfe404469632",
   "metadata": {},
   "source": [
    "## Cleanup (Optional)\n",
    "\n",
    "Let's now clean up the AgentCore Runtime created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c243e86-a214-483c-aef1-d5243f28ca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(orchestrator_launch_result.ecr_uri, orchestrator_launch_result.agent_id, orchestrator_launch_result.ecr_uri.split('/')[1])\n",
    "print(hr_launch_result.ecr_uri, hr_launch_result.agent_id, hr_launch_result.ecr_uri.split('/')[1])\n",
    "print(tech_launch_result.ecr_uri, tech_launch_result.agent_id, tech_launch_result.ecr_uri.split('/')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a6cf1416830a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_agent_runtimes(launch_result):\n",
    "    agentcore_control_client = boto3.client(\n",
    "        'bedrock-agentcore-control',\n",
    "        region_name=os.getenv(\"AWS_DEFAULT_REGION\")\n",
    "    )\n",
    "    ecr_client = boto3.client(\n",
    "        'ecr',\n",
    "        region_name=os.getenv(\"AWS_DEFAULT_REGION\")\n",
    "        \n",
    "    )\n",
    "    runtime_delete_response = agentcore_control_client.delete_agent_runtime(\n",
    "        agentRuntimeId=launch_result.agent_id,\n",
    "    )\n",
    "\n",
    "    response = ecr_client.delete_repository(\n",
    "        repositoryName=launch_result.ecr_uri.split('/')[1],\n",
    "        force=True\n",
    "    )\n",
    "\n",
    "    return response\n",
    "\n",
    "def delete_iam_roles(agentcore_iam_role):\n",
    "    iam_client = boto3.client('iam')\n",
    "    policies = iam_client.list_role_policies(\n",
    "        RoleName=agentcore_iam_role['Role']['RoleName'],\n",
    "        MaxItems=100\n",
    "    )\n",
    "\n",
    "    for policy_name in policies['PolicyNames']:\n",
    "        iam_client.delete_role_policy(\n",
    "            RoleName=agentcore_iam_role['Role']['RoleName'],\n",
    "            PolicyName=policy_name\n",
    "        )\n",
    "    iam_response = iam_client.delete_role(\n",
    "        RoleName=agentcore_iam_role['Role']['RoleName']\n",
    "    )\n",
    "    return iam_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e28dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clean_up_agent_runtimes(hr_launch_result))\n",
    "print(clean_up_agent_runtimes(tech_launch_result))\n",
    "print(clean_up_agent_runtimes(orchestrator_launch_result))\n",
    "print(delete_iam_roles(tech_agent_iam_role))\n",
    "print(delete_iam_roles(hr_agent_iam_role))\n",
    "print(delete_iam_roles(orchestrator_iam_role))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b118ad38-feeb-4d1d-9d57-e5c845becc56",
   "metadata": {},
   "source": [
    "# Congratulations!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
